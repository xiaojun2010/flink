
#### 前置工作
**`非常重要`**

1. 
* 修改宿主机host: 添加以下信息
**`非常非常非常重要`**
```
宿主机IP hbase
宿主机IP grafana
宿主机IP prometheus
宿主机IP flink
宿主机IP nginx
宿主机IP zookeeper
宿主机IP redis
宿主机IP clickhouse
宿主机IP kafka1
宿主机IP hadoop
宿主机IP yarn
宿主机IP mysql
宿主机IP nodejs
宿主机IP flume_exporter
宿主机IP kafka_exporter

```


2. 
* 确定Linux使用的 shell 是 bash 
`(特别是ubuntu,默认shell是dash)`
**`非常非常非常重要`**
```
//查看正在使用的shell
ls -l /bin/sh

//这里以ubuntu为例, 将shell更改为 bash
sudo dpkg-reconfigure dash
//在弹出的对话框选择 NO

//再次查看shell, 确认shell是bash
ls -l /bin/sh

```


3. 
* 配置docker国内镜像 ( 关于docker安装不作介绍, 注意docker版本 )
```
sudo vi /etc/docker/daemon.json
```
```json

{
 "registry-mirrors": ["https://registry.docker-cn.com"]
}

```

4. 
* 配置hadoop. ( 在win环境下开发必须，Mac环境不需要 )
```
1. 添加环境变量 HADOOP_HOME，指向 driver/Hadoop 文件夹
2. 将%HADOOP_HOME%\bin加入到path里面
```

5.
* 开发工具
1. IDEA Community Edition 2022.2.1 ( 社区版 )
3. dbeaver ( ClickHouse,Hbase,Mysql可视化工具 )
**`注意：尽量使用的版本是 7.2.5`**
```
下载地址：
https://dbeaver.io/files/7.2.5/
``` 


#### 镜像下载
* docker pull --platform linux/x86_64 grokzen/redis-cluster:6.2.11
* docker pull --platform linux/x86_64 flink:1.14.5-scala_2.11-java8
* docker pull --platform linux/x86_64 wurstmeister/kafka:2.13-2.8.1
* docker pull --platform linux/x86_64 iteblog/hbase-phoenix-docker:1.0
* docker pull --platform linux/x86_64 yandex/clickhouse-server:21.1.9.41
* docker pull --platform linux/x86_64 probablyfine/flume:2.0.0
* docker pull --platform linux/x86_64 wurstmeister/zookeeper:3.4.6
* docker pull --platform linux/x86_64 harisekhon/hadoop:2.7
* docker pull --platform linux/x86_64 mysql:5.7.25
* docker pull --platform linux/x86_64 node:20.5.1
* docker pull --platform linux/x86_64 debian:bullseye


**`==== 普罗米修斯 镜像 ========`**
* docker pull --platform linux/x86_64 prom/prometheus:v2.38.0
* docker pull --platform linux/x86_64 grafana/grafana:9.0.9
* docker pull --platform linux/x86_64 zhijunwoo/flume_exporter:latest
* docker pull --platform linux/x86_64 danielqsj/kafka-exporter:v1.6.0


#### 项目环境搭建

`建议以root身份操作以下步骤`
( **`非常重要: 是将整个 env 文件夹导入到 OS, 我这里是导入到 ubuntu 的根目录`** )

步骤 1. 
```
//进入 env 文件夹

cd env

//解压 ImoocRiskCtrlSysEnv.tar.gz, 

tar xzvf ImoocRiskCtrlSysEnv.tar.gz

```

( **`非常重要: 项目的所有命令路径都是以 env/ImoocRiskCtrlSysEnv 作为相对路径`** )
步骤 2. 
```
//进入ImoocRiskCtrlSysEnv, 

cd ImoocRiskCtrlSysEnv

```

步骤 3.
```
//执行安装脚本

sh imooc-env-setup.sh
```

#### 项目模块启动脚本
1. 风控引擎运营后台 (http://nodejs:6080)
```
sh bin/tools/start-nodejs.sh

```
2. 测试环境 flume 导数据到 Kafka
```
//启动flume
sh bin/tools/start-flume.sh

//启动kafka
sh bin/tools/start-kafka.sh

//启动 clickhouse
sh bin/tools/start-clickhouse.sh

//flume 导数据到 Kafka (这个脚本可以反复执行, 每执行1次就导入1条数据到kafka)
sh bin/test/flume-to-kafka-test.sh

//kafka 查看数据
sh bin/test/kafka-consumer-test.sh

```

3. 生产环境 flume 导数据到 Kafka
```
// 启动定时任务模块
sh start-module-crontab.sh

//kafka 查看数据
sh bin/tools/kafka-consumer.sh

//也可以在 dbeaver 查看 clickhouse 的 rods.dwd_analytics_event_from_kafka_res 表

```
